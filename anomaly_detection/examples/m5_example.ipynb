{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# anomly-detection - a fast anomaly detection library for hierarchical timeseries\n",
    "\n",
    "## Introduction\n",
    "\n",
    "`anomaly-detection` builds on Facebook's Prophet algorithm to identify unusual outliers and trends within hierarchical time-series data. In only a few lines of code, you can flag outliers and changepoints in your hierarchical time-series data.\n",
    "\n",
    "\n",
    "The example provided in this notebook were created using filtered data from the [M5 competition](https://www.kaggle.com/c/m5-forecasting-accuracy). It's intended as a reference for how this library is intended to be used, and will be updated frequently as we add more features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "# help ipython find our path\n",
    "directory = os.path.dirname(os.path.abspath(''))\n",
    "os.chdir(directory)\n",
    "\n",
    "from anomaly_detection import AnomalyDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(directory, \"examples\", \"small.csv\")\n",
    "#data = pd.read_csv(data_path)\n",
    "data = pd.read_csv(\n",
    "        \"https://raw.githubusercontent.com/facebookincubator/prophet/master/examples/example_retail_sales.csv\"\n",
    "    )"
   ]
  },
  {
   "source": [
    "### Sample Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             ds       y\n",
       "0    1992-01-01  146376\n",
       "1    1992-02-01  147079\n",
       "2    1992-03-01  159336\n",
       "3    1992-04-01  163669\n",
       "4    1992-05-01  170068\n",
       "..          ...     ...\n",
       "288  2016-01-01  400928\n",
       "289  2016-02-01  413554\n",
       "290  2016-03-01  460093\n",
       "291  2016-04-01  450935\n",
       "292  2016-05-01  471421\n",
       "\n",
       "[293 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1992-01-01</td>\n      <td>146376</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1992-02-01</td>\n      <td>147079</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992-03-01</td>\n      <td>159336</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1992-04-01</td>\n      <td>163669</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1992-05-01</td>\n      <td>170068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>2016-01-01</td>\n      <td>400928</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>2016-02-01</td>\n      <td>413554</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>2016-03-01</td>\n      <td>460093</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>2016-04-01</td>\n      <td>450935</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>2016-05-01</td>\n      <td>471421</td>\n    </tr>\n  </tbody>\n</table>\n<p>293 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "source": [
    "## Initialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector = AnomalyDetector(data=data, target=\"sales\", datetime_column=\"datetime\", additional_regressors=[\"dept_id\", \"cat_id\", \"item_id\", \"state_id\", \"store_id\"])\n",
    "\n",
    "detector = AnomalyDetector(data=data, )"
   ]
  },
  {
   "source": [
    "## Detect Anomalies & Plot Results\n",
    "\n",
    "Behind the scenes, .detect_anomalies() fits Prophet's modeling pipeline to create trend curves and 95% confidence intervals that can be used to detect unusual behavior."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.detect_anomalies()\n",
    "detector.plot_anomalies()"
   ]
  },
  {
   "source": [
    "To control the flexibility of your model, you can pass arguments directly to Prophet's `.fit()` method:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterval_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchangepoint_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Fit Prophet to the data.\n",
      "\n",
      "Parameters (passed as *args or **kwargs to Prophet)\n",
      "----------\n",
      "interval_width: float, default .95\n",
      "    Float, width of the uncertainty intervals provided\n",
      "    for the forecast. If mcmc_samples=0, this will be only the uncertainty\n",
      "    in the trend using the MAP estimate of the extrapolated generative\n",
      "    model. If mcmc.samples>0, this will be integrated over all model\n",
      "    parameters, which will include uncertainty in seasonality. In this library,\n",
      "    we override FB's default from .8 to .95 to provide more stringer\n",
      "    anomaly detection.\n",
      "growth: str, default \"linear\"\n",
      "    String 'linear' or 'logistic' to specify a linear or logistic trend.\n",
      "changepoints: list, default None \n",
      "    List of dates at which to include potential changepoints. If\n",
      "    not specified, potential changepoints are selected automatically.\n",
      "n_changepoints: int, default 25\n",
      "    Number of potential changepoints to include. Not used\n",
      "    if input `changepoints` is supplied. If `changepoints` is not supplied,\n",
      "    then n_changepoints potential changepoints are selected uniformly from\n",
      "    the first `changepoint_range` proportion of the history.\n",
      "changepoint_range: float, default .8 \n",
      "    Proportion of history in which trend changepoints will\n",
      "    be estimated. Defaults to 0.8 for the first 80%. Not used if\n",
      "    `changepoints` is specified.\n",
      "yearly_seasonality: bool, str, or int, default \"auto\" \n",
      "    If true, adds Fourier terms to model changes in annual seasonality. Pass \n",
      "    an int to manually control the number of Fourier terms added, where 10 \n",
      "    is the default and 20 creates a more flexible model but increases the \n",
      "    risk of overfitting.\n",
      "weekly_seasonality: bool, str, or int, default \"auto\"\n",
      "    Fit weekly seasonality.\n",
      "    Can be 'auto', True, False, or a number of Fourier terms to generate.\n",
      "daily_seasonality: bool, str, or int, default \"auto\"  \n",
      "    If true, adds Fourier terms to model changes in daily seasonality. Pass \n",
      "    an int to manually control the number of Fourier terms added, where 10 \n",
      "    is the default and 20 creates a more flexible model but increases the \n",
      "    risk of overfitting.\n",
      "holidays: bool, default None\n",
      "    pd.DataFrame with columns holiday (string) and ds (date type)\n",
      "    and optionally columns lower_window and upper_window which specify a\n",
      "    range of days around the date to be included as holidays.\n",
      "    lower_window=-2 will include 2 days prior to the date as holidays. Also\n",
      "    optionally can have a column prior_scale specifying the prior scale for\n",
      "    that holiday.\n",
      "seasonality_mode: str, default \"additive\"\n",
      "    'additive' (default) or 'multiplicative'. Multiplicative seasonality implies\n",
      "    that each season applies a scaling effect to the overall trend, while additive \n",
      "    seasonality implies adding seasonality to trend to arrive at delta.\n",
      "seasonality_prior_scale: float, default 10.0\n",
      "    Parameter modulating the strength of the\n",
      "    seasonality model. Larger values allow the model to fit larger seasonal\n",
      "    fluctuations, smaller values dampen the seasonality. Can be specified\n",
      "    for individual seasonalities using add_seasonality.\n",
      "holidays_prior_scale: float, default 10.0\n",
      "    Parameter modulating the strength of the holiday\n",
      "    components model, unless overridden in the holidays input.\n",
      "changepoint_prior_scale: float, default 0.05 \n",
      "    Parameter modulating the flexibility of the\n",
      "    automatic changepoint selection. Large values will allow many\n",
      "    changepoints, small values will allow few changepoints.\n",
      "mcmc_samples: int, default 0\n",
      "    Integer, if greater than 0, will do full Bayesian inference\n",
      "    with the specified number of MCMC samples. If 0, will do MAP\n",
      "    estimation, which only measures uncertainty in the trend and \n",
      "    observation noise but is much faster to run.\n",
      "uncertainty_samples: int, default 1000\n",
      "    Number of simulated draws used to estimate\n",
      "    uncertainty intervals. Settings this value to 0 or False will disable\n",
      "    uncertainty estimation and speed up the calculation.\n",
      "stan_backend: str, default None\n",
      "    str as defined in StanBackendEnum default: None - will try to\n",
      "    iterate over all available backends and find the working one\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\nthor\\onedrive\\documents\\github\\anomaly-detection\\anomaly_detection\\main.py\n",
      "\u001b[1;31mType:\u001b[0m      method\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "?detector.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    293.000000\n",
       "mean       6.440273\n",
       "std        3.463214\n",
       "min        1.000000\n",
       "25%        3.000000\n",
       "50%        6.000000\n",
       "75%        9.000000\n",
       "max       12.000000\n",
       "Name: ds, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "detector = AnomalyDetector(data=data) # Initialize a new object, otherwise you have to run .fit() and .predict() on your second run\n",
    "detector.detect_anomalies(interval_width=.80, growth=\"logistic\", holidays=True)\n",
    "detector.plot_anomalies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Results\n",
    "\n",
    "When you're finished, you can get back your original dataframe by "
   ]
  }
 ]
}